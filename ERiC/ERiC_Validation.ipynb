{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and validation of ERiC implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we test the outputs of both ELKI ERiC and our implementation of ERiC by comparing the outputs of the sample datasets from the two artificial datasets given at: https://elki-project.github.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lib import *\n",
    "\n",
    "from elki_eric import elki_eric\n",
    "import elki_parser\n",
    "import validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define methods that load the data and run both algorithms. In the *validation.py* file we compare the sizes and content of the clusters. We also output the structure so that it can be checked manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file):\n",
    "    with open(file) as f:\n",
    "        lines = [line.rstrip() for line in f if \"#\" not in line]\n",
    "        lines = [\",\".join(line.split(\" \")) for line in lines]\n",
    "    \n",
    "    df = pd.DataFrame([sub.split(\",\") for sub in lines], columns=[\"x1\",\"x2\",\"label\"])\n",
    "    X = df[[\"x1\",\"x2\"]]\n",
    "    X = X.astype(float)\n",
    "    \n",
    "    y = df[\"label\"]\n",
    "    return X, y\n",
    "    \n",
    "    \n",
    "def run_ERiC(df, k=10, min_samples=2, delta_affine=0.5, delta_dist=0.5):\n",
    "    D = df.to_numpy(dtype=np.float64)\n",
    "    point_info, partitions = make_partitions(D, k)\n",
    "\n",
    "    models, clusters = cluster_partitions(D, partitions, point_info, delta_affine, delta_dist, min_samples)\n",
    "\n",
    "    cluster_info = compute_cluster_list(clusters, D)\n",
    "    cluster_info = build_hierarchy(cluster_info, delta_affine, delta_dist, D.shape[1])\n",
    "    \n",
    "    return cluster_info    \n",
    "    \n",
    "    \n",
    "def run_ELKI_ERiC(df, k=10, min_samples=2, delta_affine=0.5, delta_dist=0.5, output_file=None):\n",
    "    D = df.to_numpy(dtype=np.float64)\n",
    "    \n",
    "    elki_eric(\n",
    "        X, \n",
    "        k=k, \n",
    "        dbscan_minpts=min_samples, \n",
    "        alpha=0.85, \n",
    "        delta_dist=delta_dist, \n",
    "        delta_affine=delta_affine, \n",
    "        output_file_name=output_file)\n",
    "    \n",
    "    df1_output = elki_parser.read_file(output_file)\n",
    "    cluster_info = elki_parser.parse_file(df1_output)\n",
    "    \n",
    "    return cluster_info   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mouse dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "***\n",
      "Run elki\n",
      "Saving ELKI results in elki_df1_output.txt\n",
      "Writing completed.\n",
      "The implementations return the same number of clusters.\n",
      "No. of clusters (our ERiC): 2\n",
      "No. of clusters (ELKI ERiC): 2\n",
      "\n",
      "The implementations return the same number of lambdas.\n",
      "No. of lambdas (our ERiC): {1: 1, 2: 1}\n",
      "No. of lambdas (ELKI ERiC): {1: 1, 2: 1}\n",
      "\n",
      "Our ERiC structure:\n",
      "Partition  1\n",
      "--- cluster 0  size: 24\n",
      "------ points\n",
      "------ parents\n",
      "[2]\n",
      "Partition  2\n",
      "--- cluster 0  size: 476\n",
      "------ points\n",
      "------ parents\n",
      "[]\n",
      "\n",
      "ELKI ERic structure\n",
      "Partition  1\n",
      "--- cluster 0  size: 24\n",
      "------ points\n",
      "------ parents\n",
      "[2]\n",
      "Partition  2\n",
      "--- cluster 0  size: 476\n",
      "------ points\n",
      "------ parents\n",
      "[]\n",
      "\n",
      "Cluster sizes were identical for lambda=1\n",
      "Cluster values are identical for lambda=1\n",
      "Cluster sizes were identical for lambda=2\n",
      "Cluster values are identical for lambda=2\n",
      "\n",
      "Validation result: The outputs of the algorithms are identical.\n"
     ]
    }
   ],
   "source": [
    "X, y = load_dataset(\"sample_dataset/mouse.csv\")\n",
    "\n",
    "# Our implementation\n",
    "cluster_info_eric = run_ERiC(X)\n",
    "# ELKI implementation\n",
    "elki_output_df1 = \"elki_df1_output.txt\"\n",
    "cluster_info_elki_eric = run_ELKI_ERiC(X, output_file=elki_output_df1)\n",
    "\n",
    "# Run validation\n",
    "validation.validate(cluster_info_eric, cluster_info_elki_eric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vary density dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "***\n",
      "Run elki\n",
      "Saving ELKI results in elki_df2_output.txt\n",
      "Writing completed.\n",
      "The implementations return the same number of clusters.\n",
      "No. of clusters (our ERiC): 2\n",
      "No. of clusters (ELKI ERiC): 2\n",
      "\n",
      "The implementations return the same number of lambdas.\n",
      "No. of lambdas (our ERiC): {1: 1, 2: 1}\n",
      "No. of lambdas (ELKI ERiC): {1: 1, 2: 1}\n",
      "\n",
      "Our ERiC structure:\n",
      "Partition  1\n",
      "--- cluster 0  size: 3\n",
      "------ points\n",
      "------ parents\n",
      "[2]\n",
      "Partition  2\n",
      "--- cluster 0  size: 147\n",
      "------ points\n",
      "------ parents\n",
      "[]\n",
      "\n",
      "ELKI ERic structure\n",
      "Partition  1\n",
      "--- cluster 0  size: 3\n",
      "------ points\n",
      "------ parents\n",
      "[2]\n",
      "Partition  2\n",
      "--- cluster 0  size: 147\n",
      "------ points\n",
      "------ parents\n",
      "[]\n",
      "\n",
      "Cluster sizes were identical for lambda=1\n",
      "Cluster values are identical for lambda=1\n",
      "Cluster sizes were identical for lambda=2\n",
      "Cluster values are identical for lambda=2\n",
      "\n",
      "Validation result: The outputs of the algorithms are identical.\n"
     ]
    }
   ],
   "source": [
    "X, y = load_dataset(\"sample_dataset/vary_density.csv\")\n",
    "\n",
    "# Our implementation\n",
    "cluster_info_eric = run_ERiC(X)\n",
    "# ELKI implementation\n",
    "elki_output_df2 = \"elki_df2_output.txt\"\n",
    "cluster_info_elki_eric = run_ELKI_ERiC(X, output_file=elki_output_df2)\n",
    "\n",
    "# Run validation\n",
    "validation.validate(cluster_info_eric, cluster_info_elki_eric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, the outputs for both sample datasets are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
