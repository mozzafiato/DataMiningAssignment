{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auxiliarymethods import datasets as dp\n",
    "from auxiliarymethods.reader import tud_to_networkx\n",
    "import auxiliarymethods.auxiliary_methods as aux\n",
    "import os\n",
    "import numpy as np\n",
    "from lib import *\n",
    "import pickle\n",
    "from elki_eric import elki_eric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter\n",
    "iterations = 5 # weierfeiler-lehman iterations\n",
    "k = 60\n",
    "alpha = .85\n",
    "delta_affine = .3\n",
    "delta_dist = .3\n",
    "min_samples = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling\n",
    "pickle_path = 'pickles'\n",
    "# files can be found here\n",
    "# https://ucloud.univie.ac.at/index.php/s/pjLEBg8rCJWdaJ2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def load_csv(path):\n",
    "    return np.loadtxt(path, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(\"kernels\", \"without_labels\")\n",
    "ds_name = \"IMDB-BINARY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gram Matrix for the Weisfeiler-Lehman subtree kernel\n",
    "try:\n",
    "    gram = load_csv(os.path.join(base_path,f\"{ds_name}_gram_matrix_wl{iterations}.csv\"))\n",
    "except:\n",
    "    ds_name = \"IMDB-BINARY\"\n",
    "    classes = dp.get_dataset(ds_name)\n",
    "    G = tud_to_networkx(ds_name)\n",
    "    print(f\"Number of graphs in data set is {len(G)}\")\n",
    "    print(f\"Number of classes {len(set(classes.tolist()))}\")\n",
    "    gram = load_csv(os.path.join(base_path,f\"{ds_name}_gram_matrix_wl{iterations}.csv\"))\n",
    "finally:\n",
    "    gram = aux.normalize_gram_matrix(gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "elki_output = elki_eric(gram, k=k, dbscan_minpts=min_samples, alpha=alpha, delta_dist=delta_dist, delta_affine=delta_affine, memory='60G')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(f\"elki/elki_output.txt_{iterations}_{k}_{alpha}_{delta_affine}_{delta_dist}_{min_samples}\", \"w\") as f: f.write(elki_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parser import draw_graph, parse_file\n",
    "\n",
    "\n",
    "draw_graph(parse_file(elki_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "e2cf64d48c5d50ea1e2870a475fdf6588c9274e8b6509a1571fe1129ef0ff186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
